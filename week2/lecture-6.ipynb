{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ce827a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> \n",
    "\n",
    "### DATA 22100 - Introduction to Machine Learning\n",
    "\n",
    "</div>\n",
    "\n",
    "<img src=\"https://github.com/david-biron/DATA221imgs/blob/main/UChicago_DSI.png?raw=true\" align=\"right\" alt=\"UC-DSI\" width=\"300\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb79567",
   "metadata": {},
   "source": [
    "<center> \n",
    "\n",
    "# Gradient Descent (in brief) \n",
    "    \n",
    "</center> \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a7ae7",
   "metadata": {},
   "source": [
    "## The gradient of a function $f: {\\cal R}^n \\to {\\cal R}$\n",
    "\n",
    "(not a theoretical course $\\to$ examples rather than formal derivations)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6f794",
   "metadata": {},
   "source": [
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_definition.png?raw=true\" width=\"50\" height=\"\"> | The **gradient** of  $f(\\beta_0, \\beta_1, \\dots, \\beta_n): {\\cal R}^n \\to {\\cal R}$, denoted $\\nabla_\\beta f$, is a row (vector) of  <br> the partial derivatives of $f$ with respect to the each of the $\\beta_i$'s. |\n",
    "\n",
    "\n",
    "\n",
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_example.png?raw=true\" width=\"50\" height=\"\"> | Consider the functions $$f(\\beta_1, \\beta_2) = \\hat y = \\beta_1 x_1 + \\beta_2 x_2$$ <br> $\\nabla_\\beta \\hat y  = $ ? |\n",
    "\n",
    "Each partial derivative is calculated like a 'regular' derivative with respect to a given $\\beta_i$, while *treating all the others as constant*. \n",
    "\n",
    "$$\\begin{eqnarray} \n",
    "&& \\frac {\\partial \\hat y}{\\beta_1} = x_1 \\ \\ \\ , \\ \\ \\ \\frac {\\partial \\hat y}{\\beta_1} = x_2 \\\\ \n",
    "&& \\\\ \n",
    "\\rightarrow && \\nabla_\\beta \\hat y = \\left[ x_1, x_2 \\right] \n",
    "\\end{eqnarray}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f2aab",
   "metadata": {},
   "source": [
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_comment.png?raw=true\" width=\"50\" height=\"\"> | The **chain rule** for differentiation states that working out how the <br> composition $f\\left[g(x)\\right]$ changes when $x$ is changed (by a small amount) <br> can 'go through $g$':  |\n",
    "* Work out by what factor $f(g)$ would change if $g$ changes (by a small amount).\n",
    "* Work out by what factor $g(x)$ would change if $x$ changes (by a small amount).\n",
    "* Multuply the two factors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eba434",
   "metadata": {},
   "source": [
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_example.png?raw=true\" width=\"50\" height=\"\"> | Consider the functions $$\\hat p\\left[\\hat y(\\beta_1, \\beta_2)\\right] = \\frac 1{1+e^{-\\hat y}} = \\frac 1{1+e^{-\\left(\\beta_1 x_1 + \\beta_2 x_2\\right)}}$$ <br> $\\nabla_\\beta \\hat p  = $ ? |\n",
    "\n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "\n",
    "$$\\begin{equation*}\n",
    "&& \\nabla_{\\beta_1} \\hat p = \\frac{\\partial \\hat p}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial \\hat \\beta_1} = \\frac {e^{-\\hat y}}{\\left(1+e^{-\\hat y}\\right)^2} \\cdot x_1 \\\\\n",
    "&& \\nabla_{\\beta_2} \\hat p = \\frac{\\partial \\hat p}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial \\hat \\beta_2} = \\frac {e^{-\\hat y}}{\\left(1+e^{-\\hat y}\\right)^2} \\cdot x_2 \\\\\n",
    "&& \\\\ \n",
    "\\rightarrow && \\nabla_\\beta \\hat p = \\frac {e^{-\\left(\\beta_1 x_1 + \\beta_2 x_2\\right)}}{\\left(1+e^{-\\left(\\beta_1 x_1 + \\beta_2 x_2\\right)}\\right)^2} \\left[ x_1, x_2  \\right]\n",
    "\\end{equation*}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee85e41",
   "metadata": {},
   "source": [
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_comment.png?raw=true\" width=\"50\" height=\"\"> | The **gradient** is a vector that poits at the **direction of steepest ascent** of the function. <br> This can be shown by considering [directional derivatives](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/directional-derivative-introduction), properties of the [inner (dot) product](https://www.khanacademy.org/math/multivariable-calculus/thinking-about-multivariable-function/x786f2022:vectors-and-matrices/a/dot-products-mvc), <br> and the fact that $\\text{argmax} \\left[ \\cos(\\theta) \\right]=0$. We will demonstrate this with two examples.  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac7f87",
   "metadata": {},
   "source": [
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_example.png?raw=true\" width=\"50\" height=\"\"> | Consider the function $$ f:{\\cal R}^2 \\to {\\cal R} $$ $$ f\\left(x_1, x_2\\right) = x_1^2 + x_2^2$$  | \n",
    "\n",
    "<img src=\"https://github.com/david-biron/DATA221imgs/blob/main/PartialDerivativesParabolicSurface.png?raw=true\" width=\"400\" height=\"\">\n",
    "\n",
    "$$\n",
    "\\nabla_x f = \\left[\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\right] = 2 \\left[ x_1, x_2 \\right] \n",
    "$$ \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/david-biron/DATA221imgs/blob/main/PartialDerivativesParabolicContoursGradients.png?raw=true\" width=\"400\" height=\"\">\n",
    "\n",
    "\n",
    "**Note**: \n",
    "\n",
    "* Gradiesnts at various points on the [**contour plot**](https://www.khanacademy.org/math/multivariable-calculus/thinking-about-multivariable-function/ways-to-represent-multivariable-functions/a/contour-maps) always point toward the direction of steepest ascent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d3443",
   "metadata": {},
   "source": [
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_example.png?raw=true\" width=\"50\" height=\"\"> | Consider the function $$ f:{\\cal R}^2 \\to {\\cal R} $$ $$ f\\left(x_1, x_2\\right) = e^{-\\left(x_1^2 + x_2^2\\right)}$$  | \n",
    "\n",
    "<img src=\"https://github.com/david-biron/DATA221imgs/blob/main/PartialDerivativesNormalSurface.png?raw=true\" width=\"400\" height=\"\">\n",
    "\n",
    "$$\n",
    "\\nabla_x f = \\left[\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2} \\right] = {\\large {\\color{red} -}}2e^{-\\left(x_1^2 + x_2^2\\right)} \\left[ x_1, x_2 \\right] \n",
    "$$ \n",
    "\n",
    "\n",
    "<img src=\"https://github.com/david-biron/DATA221imgs/blob/main/PartialDerivativesNormalContoursGradients.png?raw=true\" width=\"400\" height=\"\">\n",
    "\n",
    "\n",
    "**Note**: \n",
    "\n",
    "* If the gradient points towards the steepest ascent (see plot above) then **Minus the gradiesnt**, i.e., a vector that points in the opposite direction, would point in the direction of **steepest descent**.\n",
    "\n",
    "* BTW, a vector perpendicular to the graidient would be tangent to a contour line ('isoline'). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bf74a",
   "metadata": {},
   "source": [
    "## The basic Gradient Descent algorithm \n",
    "\n",
    "* A loss function of a machine learning model measures how far an estimated value is from its true value as a function of the model parameters.\n",
    "\n",
    "* A set of parameters may be 'good' if it minimizes the loss function.\n",
    "\n",
    "* Thus, finding the best values for the model parameters is like finding a valley in the 'landscape' specified by the loss function. Training is a minimization process. \n",
    "\n",
    "* Since gradients point 'uphill', a numerical minimization procedure can start somewhere and descend 'downhill' by moving opposite to the gradient.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367eacaa",
   "metadata": {},
   "source": [
    "#### Goal: minimize $f(\\beta_1, \\beta_2, \\dots \\beta_n)$ \n",
    "\n",
    "#### Algortithm: take steps proportional to ${\\color{red}-}\\nabla_\\beta f$\n",
    "\n",
    "$$ \n",
    "\\begin{pmatrix}\n",
    "\\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_n\n",
    "\\end{pmatrix}_{t+1} =  \n",
    "\\begin{pmatrix}\n",
    "\\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_n\n",
    "\\end{pmatrix}_{t} {\\large {\\color{red} - }} \\ \\gamma_t \\ \\nabla_\\beta^\\top f = \n",
    "\\begin{pmatrix}\n",
    "\\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_n\n",
    "\\end{pmatrix}_{t} {\\large {\\color{red} - }} \\ \\gamma_t \\\n",
    "\\begin{pmatrix}\n",
    "\\frac{\\partial f}{\\partial \\beta_1} \\\\ \\frac{\\partial f}{\\partial \\beta_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial \\beta_n}\n",
    "\\end{pmatrix}_{t}\n",
    "$$\n",
    "\n",
    "* $\\gamma_t$ is the **learning rate** at step $t$ (it could be constant throughout the optimization/training or it could change). \n",
    "\n",
    "* The transpose notation is just a reminder that a gradient is a row vector and should become turned into a column before adding it to the column of coefficients. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb88ca",
   "metadata": {},
   "source": [
    "#### If all goes well \n",
    "\n",
    "$$ \n",
    "\\text{loss_func} \\left[ \\begin{pmatrix}\n",
    "\\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_n\n",
    "\\end{pmatrix}_{0} \\right] \\geq \n",
    "\\text{loss_func} \\left[ \\begin{pmatrix}\n",
    "\\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_n\n",
    "\\end{pmatrix}_{1} \\right] \\geq \n",
    "\\text{loss_func} \\left[ \\begin{pmatrix}\n",
    "\\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_n\n",
    "\\end{pmatrix}_{2} \\right] \\geq \n",
    "\\dots\n",
    "$$ \n",
    "\n",
    "<br> \n",
    "\n",
    "**However**\n",
    "* If the learning rate is too small, gradient descent can be slow.\n",
    "* If the learning rate is too large, gradient descent will fail to converge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457aa98",
   "metadata": {},
   "source": [
    "### Example: gradient descent witha  simple function \n",
    "\n",
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_example.png?raw=true\" width=\"50\" height=\"\"> | Consider the function $$ f:{\\cal R}^2 \\to {\\cal R} $$ $$ f\\left[\\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\end{pmatrix}\\right] =   \\beta_1^2 + \\beta_1 \\beta_2 + 10 \\beta_2^2 -5\\beta_1 -3\\beta_2$$  | \n",
    "\n",
    "Show the progression of the gradient descent algorithm with a learning rate of $\\gamma = 0.085$ and the starting point $$ \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\end{pmatrix}_0 = \\begin{pmatrix} -3 \\\\ -1 \\end{pmatrix} $$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "&& \\nabla_\\beta f = \\left[2\\beta_1 + \\beta_2-5, \\ \\ \\beta_1 + 20\\beta_2 - 3  \\right] \\\\\n",
    "\\rightarrow && \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\end{pmatrix}_1 = \\begin{pmatrix} -3 \\\\ -1 \\end{pmatrix}_0  - 0.085 \\begin{pmatrix} -12 \\\\ -26 \\end{pmatrix} \\simeq \\begin{pmatrix} -2 \\\\ 1.2 \\end{pmatrix} \\\\\n",
    "\\rightarrow && \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\end{pmatrix}_2 \\simeq \\begin{pmatrix} -2 \\\\ 1.2 \\end{pmatrix}_0  - 0.085 \\begin{pmatrix} -7.8 \\\\ 19 \\end{pmatrix} \\simeq \\begin{pmatrix} -1.3 \\\\ -0.4 \\end{pmatrix} \\\\\n",
    "\\rightarrow && \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\end{pmatrix}_2 \\simeq \\begin{pmatrix} -1.3 \\\\ -0.4 \\end{pmatrix} - \\dots \\simeq \\begin{pmatrix} -0.3 \\\\ 0.6 \\end{pmatrix} \\\\\n",
    "&& \\vdots\n",
    "\\end{eqnarray}$$  \n",
    "\n",
    "<img src=\"https://github.com/david-biron/DATA221imgs/blob/main/GradientDescentExample1.png?raw=true\" width=\"450\" height=\"\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb7d7a3",
   "metadata": {},
   "source": [
    "### Example: the negative log likelihood loss function (e.g.,) for logistic regression\n",
    "\n",
    "|   |   |\n",
    "|:--|:--|\n",
    "| <img src=\"https://github.com/david-biron/DATA221imgs/blob/main/icon_example.png?raw=true\" width=\"50\" height=\"\"> | Consider the negative log likelihood loss function for classifiers (e.g., for logistic regression) $$\\begin{eqnarray} && \\log {\\cal L} = \\sum_{i=1}^N  \\left[ y_i \\log \\hat p_i \\ + \\ \\left( 1-y_i \\right) \\log \\left( 1 - \\hat p_i \\right) \\right] \\\\ \\text{where } && \\hat p_i\\left[\\hat y_i\\right] = \\frac 1{1+e^{-\\hat y_i}} \\ \\ \\ \\text{ and }  \\ \\ \\ \\hat y_i(\\beta_1, \\beta_2) = \\beta_1 x_{1,i} + \\beta_2 x_{2,i} \\end{eqnarray}$$  Find the gradient descent updating rule with a constant learning rate, $\\gamma$. | \n",
    "\n",
    "<br> \n",
    "<br>\n",
    "<br> \n",
    "\n",
    "* ${\\cal L}$ depends on $\\beta_1$ and $\\beta_2$ thorugh every $\\hat  p_i$ (not through $y_i$ because they are given labels). \n",
    "\n",
    "* Note that $ \\ \\ \\ \\hat p_i = \\frac 1{1+e^{-\\hat y_i}} \\ \\ \\rightarrow \\ \\ 1 - \\hat p_i = \\frac {e^{-\\hat y_i}}{1+e^{-\\hat y_i}}$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\boxed{ \\nabla_{\\beta_{\\color{red} 1}} {\\cal L} }  && \\underbrace{=}_{\\text{chain rule}} \\sum_i \\frac{\\partial {\\cal L}}{\\partial \\hat p_i} \\frac{\\partial \\hat p_i}{\\partial \\beta_1} \\\\\n",
    "&& \\underbrace{=}_{log'(x)=1/x} \\sum_i \\left[ \\frac {y_i}{\\hat p_i} \\frac{\\partial \\hat p_i}{\\partial \\beta_1} -\n",
    "\\left(\\frac {1 - y_i}{1 - \\hat p_i}\\right) \\frac{\\partial \\hat p_i}{\\partial \\beta_1} \\right] \\\\\n",
    "&& \\underbrace{=}_{\\text{previous example}} \\sum_i \\left[ \\frac {y_i}{\\hat p_i} \\frac {e^{-\\hat y}}{\\left(1+e^{-\\hat y}\\right)^2} \\cdot  x_{{\\color{red} 1},i} -\n",
    "\\left(\\frac {1 - y_i}{1 - \\hat p_i}\\right) \\frac {e^{-\\hat y}}{\\left(1+e^{-\\hat y}\\right)^2} \\cdot  x_{{\\color{red} 1},i} \\right] \\\\\n",
    "&& \\underbrace{=}_{\\text{comment above}} \\sum_i \\left[ \\frac {y_i}{\\hat p_i} \\hat p_i \\left(1-\\hat p_i\\right) \\cdot  x_{{\\color{red} 1},i} -\n",
    "\\left(\\frac {1 - y_i}{1 - \\hat p_i}\\right) \\hat p_i \\left(1-\\hat p_i\\right) \\cdot  x_{{\\color{red} 1},i} \\right] \\\\\n",
    "&& = \\sum_i \\left[ y_i \\left(1-\\hat p_i\\right)  -\n",
    "\\hat p_i   \\left(1 - y_i\\right) \\right]  x_{{\\color{red} 1},i}  \\\\\n",
    "&& = \\boxed{ \\sum_i  \\left(y_i-\\hat p_i\\right) x_{{\\color{red} 1},i} } \\\\\n",
    "\\end{eqnarray}$$ \n",
    "\n",
    "Such that \n",
    "$$ \\beta_{{\\color{red} 1}}^{t+1} = \\beta_{{\\color{red} 1}}^{t} - \\gamma \\sum_i  \\left[y_i-\\hat p_{i}^{\\ t} \\right] x_{{\\color{red} 1},i} \\ \\ \\ \\text{ where }  \\ \\ \\  \\hat p_{i}^{\\ t} = \\frac 1{1+e^{-\\left( \\beta_{1}^{t} x_{1,i} + \\beta_{2}^{t} x_{2,i} \\right)}}$$ \n",
    "\n",
    "And likewise \n",
    "$$ \\beta_{{\\color{blue} 2}}^{t+1} = \\beta_{{\\color{blue} 2}}^{t} - \\gamma \\sum_i  \\left[y_i-\\hat p_{i}^{\\ t} \\right] x_{{\\color{blue} 2},i} \\ \\ \\ \\text{ where }  \\ \\ \\  \\hat p_{i}^{\\ t} = \\frac 1{1+e^{-\\left( \\beta_{1}^{t} x_{1,i} + \\beta_{2}^{t} x_{2,i} \\right)}}$$ \n",
    "\n",
    "(FYI, matrix notation makes this easier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d7e7a1",
   "metadata": {},
   "source": [
    "### Acomment about Stochastic Gradient Descent\n",
    "\n",
    "* Gradient descent can be computationally expensive since large datasets and a medium to large number of features are not uncommon. \n",
    "\n",
    "* **Stochastic Gradient Descent (SGD)** is (one of several) variants that can be computed faster but, in principle, is less exact. \n",
    "\n",
    "* SGD randomly selects *one data point* at each step to calculate the derivatives. \n",
    "\n",
    "* Alternatively, SGD may sample a small number of data points instead of just one (**mini-batch** gradient descent). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc621df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
